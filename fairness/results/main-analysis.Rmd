---
title: "Benchmark results analysis"
author: "cscheid"
date: "2/9/2018"
output: html_document
---

# Function definitions, setup

```{r}
library(stringr)
library(ggplot2)
library(dplyr)
library(magrittr)
library(corrplot)
library(robust)
library(purrr)
```

We'll be showing many different charts with a large number of different attributes, so a good
categorical color scale is helpful. We're using [d3](https://d3js.org) `d3.schemeCategory10` and `d3.schemeCategory20`.

```{r}
# Use these for more than 10 algorithms
colors_20 = c(
  "#1f77b4", "#aec7e8", "#ff7f0e", "#ffbb78", "#2ca02c", "#98df8a", "#d62728", "#ff9896",
  "#9467bd", "#c5b0d5", "#8c564b", "#c49c94", "#e377c2", "#f7b6d2", "#7f7f7f", "#c7c7c7",
  "#bcbd22", "#dbdb8d", "#17becf", "#9edae5")

# Use these for 10 or fewer algorithms
colors_10 = c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")

catscale10  = scale_colour_manual(values=colors_10)
catscale10_2 = scale_fill_manual(values=colors_10)

catscale20  = scale_colour_manual(values=colors_20)
catscale20_2 = scale_fill_manual(values=colors_20)

create_sensitivity_summary = function(df, x_var, y_var) {
  quo_x_var = enquo(x_var)
  quo_y_var = enquo(y_var)
  #x_mean_name = paste0("mean_", quo_name(quo_x_var))
  #y_mean_name = paste0("mean_", quo_name(quo_y_var))
  #x_sd_name = paste0("sd_", quo_name(quo_x_var))
  #y_sd_name = paste0("sd_", quo_name(quo_y_var))

  sensitivity_summary = 
    df %>% 
    group_by(algorithm) %>% 
    summarise(x_sd=sd(!!quo_x_var), x_mean=mean(!!quo_x_var), 
              y_sd=sd(!!quo_y_var), y_mean=mean(!!quo_y_var))
  sensitivity_summary
}

basic_sensitivity_plot = function(sensitivity_summary, x_var, y_var) {
  ggplot(sensitivity_summary, aes(x=x_mean, y=y_mean, colour=algorithm)) + catscale10 + catscale10_2 +
    xlab(quo_name(enquo(x_var))) + ylab(quo_name(enquo(y_var)))
}

plot_lines_sensitity_summary = function(basic_plot) {
  basic_plot + 
    geom_segment(aes(x=x_mean - x_sd, xend = x_mean + x_sd,
                     y=y_mean, yend = y_mean,
                     colour=algorithm)) + 
    geom_segment(aes(x=x_mean, xend = x_mean,
                     y=y_mean - y_sd, yend = y_mean + y_sd,
                     colour=algorithm))
}

plot_ellipses_sensitity_summary = function(basic_plot) {
  basic_plot + stat_ellipse(level=0.5, geom="polygon", aes(fill=algorithm), alpha=0.2) + stat_ellipse(level=0.5, fill=NA)
}

plot_rects_sensitivity_summary = function(basic_plot) {
  aesthetics1 = aes(xmin = x_mean - 0.5 * x_sd,   
                   xmax = x_mean + 0.5 * x_sd,
                   ymin = y_mean - 0.5 * y_sd, 
                   ymax = y_mean + 0.5 * y_sd,
                   fill=algorithm)
  aesthetics2 = aes(xmin = x_mean - 0.5 * x_sd,   
                   xmax = x_mean + 0.5 * x_sd,
                   ymin = y_mean - 0.5 * y_sd, 
                   ymax = y_mean + 0.5 * y_sd,
                   colour=algorithm)
  basic_plot +
    geom_rect(aesthetics1, alpha=0.15) +
    geom_rect(aesthetics2, fill=NA)
}

do_it_all = function(name, var1, var2, check.names=FALSE) {
  df = read.csv(str_c(name, ".csv"), check.names=check.names)
  
  x_var = as.name(var1)
  y_var = as.name(var2)

  sensitivity_summary = create_sensitivity_summary(df, !!x_var, !!y_var)

  basic_plot = basic_sensitivity_plot(sensitivity_summary, !!x_var, !!y_var) + ggtitle(name)
  
  plot_rects_sensitivity_summary(basic_plot)
}

nb_measure_comparison = function(name, measure) {
  num <- read.csv(str_c(name, "_numerical.csv"), check.names=FALSE)
  nbs <- read.csv(str_c(name, "_numerical-binsensitive.csv"), check.names=FALSE)
  
  var1 <- as.name(str_c(measure, "-numerical"))
  var2 <- as.name(str_c(measure, "-binsensitive"))
  
  df <- inner_join(num, nbs, by=c("algorithm", "run-id"), suffix = c("-numerical", "-binsensitive"))
  df$name = name
  df
  # return (df %>% select(!!var1, !!var2, "run-id", "algorithm", "name"))
}
```

# Preliminaries

# Paper figures

## Preprocessing tradeoffs

```{r}
plot_tradeoff = function(measure, dataset) {
  df = nb_measure_comparison(dataset, measure)
  var1 <- as.name(str_c(measure, "-numerical"))
  var2 <- as.name(str_c(measure, "-binsensitive"))
  ggplot(df %>% filter(!(algorithm %in% c("LR", "SVM", "GaussianNB"))), aes_q(x=var1, y=var2, colour=quote(algorithm))) + catscale10 + catscale10_2 + geom_abline(a=0,b=1, colour="gray") +
    geom_point() + ggtitle(str_c(dataset, ", measure: ", measure)) 
}

# measure = "accuracy"
p = plot_tradeoff("accuracy", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-accuracy.png", p)

p = plot_tradeoff("DIavgall", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-DIavgall.png", p)

p = plot_tradeoff("DIbinary", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-DIbinary.png", p)
```
```{r}
p = plot_tradeoff("DIbinary", "german_sex-age")
print(p)
```

## Algorithm sensitivity

```{r}
plot_sensitivity = function(df, var1, var2) {
  x_var = as.name(var1)
  y_var = as.name(var2)

  sensitivity_summary = create_sensitivity_summary(df, !!x_var, !!y_var)
  basic_plot = basic_sensitivity_plot(sensitivity_summary, !!x_var, !!y_var)
  plot_rects_sensitivity_summary(basic_plot)
}

algos_to_plot = c(
  "ZafarFairness", "Calders", "SVM", 
  "Feldman-SVM", "DecisionTree", 
  "Feldman-DecisionTree", "Kamishima")

make_sensitivity_figure = function(name, var1="DIbinary", var2="accuracy") {
  df = read.csv(name, check.names=TRUE) %>% 
    filter(algorithm %in% algos_to_plot) %>% 
    mutate(algorithm=recode(algorithm, ZafarFairness="Zafar")) # rename to Zafar for clarity
  
  plot_sensitivity(df, var1, var2)
}

p = make_sensitivity_figure("adult_sex_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, sex attribute")
print(p)
ggsave("paper-figures/adult_sex_sensitivity.png", p)

p = make_sensitivity_figure("adult_race_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, race attribute")
print(p)
ggsave("paper-figures/adult_race_sensitivity.png", p)

p = make_sensitivity_figure("adult_race-sex_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, sex+race combined attribute")
print(p)
ggsave("paper-figures/adult_race-sex_sensitivity.png", p)

```

```{r}
p = make_sensitivity_figure("propublica-violent-recidivism_race_numerical-binsensitive.csv", "DIavgall") +
  ggtitle("Propublica violent recidivism dataset, race attribute")
print(p)
```

### Parameter setting tradeoffs

Algorithms can state what their parameter grid search values are, since these can provide significantly different results:

```{r}
param_regex = "[01].[0-9]+"

adult_race_params = read.csv("paramgrid-results/Feldman-SVM-DIavgall_adult_race_numerical-binsensitive.csv", stringsAsFactors = FALSE, check.names=TRUE) %>% 
    mutate(lambda=as.numeric(str_extract(params, param_regex)))
p = ggplot(adult_race_params, aes(x=DIavgall, y=accuracy, colour=lambda)) + geom_point() + ggtitle("Adult dataset, race attribute")
print(p)
ggsave("paper-figures/adult_race_params_feldman.png", p)
```

```{r}
ricci_race_params = read.csv("ricci_Race_numerical-binsensitive.csv", stringsAsFactors = FALSE, check.names=FALSE) 
# ggplot(ricci_race_params, aes(x=DIavgall, y=`Race-calibration-`, colour=c)) + geom_point()
#adult_race_params = read.csv("ZafarFairness-DIavgall_adult_race_numerical-binsensitive.csv", #stringsAsFactors = FALSE, check.names=TRUE) %>% 
#  mutate(c=as.numeric(str_extract(params, param_regex))) %>% 
#  filter(c>=0.01) # skip low range of parameter setting to avoid overweighting the correlation matrices

p = ggplot(ricci_race_params, aes(x=DIavgall, y=accuracy, colour=algorithm)) + geom_point() + ggtitle("Ricci dataset, Race attribute")
print(p)
ggsave("paper-figures/ricci_race_params_zafar.png", p)
```

### Proliferation of measures

```{r}
compute_measure_correlation_matrix = function(df, measures) {
  cor(df[,measures])
  
  # ignore robust correlation for now
  #m = matrix(0, nrow=length(measures), ncol=length(measures))
  # colnames(m) = measures
  #rownames(m) = measures
  #for (i in 1:length(measures)) {
  #  for (j in 1:length(measures)) {
  #    x = df[[measures[[i]]]]
  #    y = df[[measures[[j]]]]
  #    if (sd(x) < 0.0001 || sd(y) < 0.0001) {
  #      m[i,j] = 0.0 # kludge
  #    } else {
  #      # some metrics have large outliers, which hoses a naive correlation calculation.
  #      # we'll use a robust correlation routine
  #      # we perturb the points minimally because otherwise robust:covRob crashes..
  #      tdf <- data.frame(x=x+rnorm(length(x))*0.001, 
  #                        y=y+rnorm(length(x))*0.001)
  #      if (cor(x, y) > 0.9999) {
  #        m[i, j] = cor(x, y)
  #      } else {
  #        r = covRob(tdf, corr=TRUE)
  #        # I could probably do all of this at once, but I don't want to deal with constant
  #        # columns _and_ robust calculations at once
  #        m[i,j] = r$cov[[1,2]]
  #      }
  #    }
  #  }
  #}
  #m
}
```

For Ricci and Zafar:

```{r}
consistent_measures = c("DIbinary", "DIavgall", "CV", "TNR", "TPR", "accuracy", "BCR", "MCC")

load_and_compute_combined_datasets = function(dataset_names, attribute) {
  measures = c(consistent_measures[1:3], str_c(attribute, "-calibration-"), 
   consistent_measures[-(1:3)], str_c(attribute, "-accuracy"), 
   "0-accuracy", "1-accuracy", str_c(attribute, "-calibration+"),
   str_c(attribute, "-TNR"), str_c(attribute, "-TPR"))

  datasets = lapply(dataset_names, function(dataset_name) {
    dataset = read.csv(str_c(dataset_name, "_", attribute, "_numerical-binsensitive.csv"), stringsAsFactors = FALSE, check.names=FALSE) 
    reduced_dataset = dataset[,c(measures, "algorithm")]
    reduced_dataset$name = dataset_name
    reduced_dataset
  })
  do.call(rbind, datasets)
}
load_and_compute_correlation_matrix = function(dataset_names, attribute) {
  measures = c(consistent_measures[1:3], str_c(attribute, "-calibration-"), 
   consistent_measures[-(1:3)], str_c(attribute, "-accuracy"), 
   "0-accuracy", "1-accuracy", str_c(attribute, "-calibration+"),
   str_c(attribute, "-TNR"), str_c(attribute, "-TPR"))

    compute_measure_correlation_matrix(load_and_compute_combined_datasets(dataset_names, attribute), measures)
}

#consistent_measures = c("DIbinary", "DIavgall", "CV", "TNR", "TPR", "accuracy", "BCR", "MCC")

#numeric_columns = sapply(ricci_race_params, class) == "numeric"
#ricci_measures = subset(colnames(ricci_race_params), numeric_columns)

# ricci_measures
#ricci_m = compute_measure_correlation_matrix(
# ricci_race_params, 
# c(consistent_measures[1:3], "Race-calibration-", 
#   consistent_measures[-(1:3)], "Race-accuracy", "0-accuracy", "1-accuracy", "Race-calibration+",
#   "Race-TNR", "Race-TPR"))

# symmetrize the matrix manually because robust correlation as we compute it is not
# necessarily symmetric


# BUG: I'm having a hard time making RMarkDown save this to a file :( type this in your
# console instead...
#
# png(file="paper-figures/ricci_measures_correlation.png")

# corrplot(ricci_m, method="color", order="original")
```

For Adult and Feldman-SVM:

```{r}
# numeric_columns = sapply(adult_race_params, class) == "numeric"
# adult_measures = subset(colnames(adult_race_params), numeric_columns)

# adult_m = compute_measure_correlation_matrix(
#   adult_race_params, 
#   c("X1.accuracy", "TPR", "race.TPR", "TNR", "X0.accuracy", "race.TNR", "race.calibration.", "BCR", "MCC", "accuracy", "race.accuracy", "race.calibration..1", "CV", "DIbinary", "DIavgall"))
  #c(consistent_measures[1:3], "race.calibration..1", 
  #  consistent_measures[-(1:3)], "race.accuracy", "X0.accuracy", "X1.accuracy", "race.calibration.",
  #  "race.TPR", "race.TNR"))

# BUG: I'm having a hard time making RMarkDown save this to a file :( type this in your
# console instead...
#
# corrplot(adult_m, method="color", order="original")
```

# Multiple sensitive attributes

```{r}
race = read.csv("adult_race_numerical.csv")
sex = read.csv("adult_sex_numerical.csv")
both = read.csv("adult_race-sex_numerical.csv")
race$repair = "race"
sex$repair = "sex"
both$repair = "both"

df = rbind(race, sex, both) %>% 
  filter(algorithm %in% c("ZafarFairness", "Calders", "Kamishima", "Feldman-GaussianNB"))
df$repair <- factor(df$repair, levels = c("race", "sex", "both"))
p = ggplot(df, aes(x=DIavgall, y=accuracy, colour=repair)) + catscale10 + catscale10_2 + stat_ellipse(geom="polygon", level=0.5, alpha=0.1) + geom_point(alpha=0.3) + ggtitle("Adult dataset") + facet_wrap(~algorithm)
print(p)
ggsave("paper-figures/adult-multivariate-repair-tradeoff.png", p)
```

```{r}
age = read.csv("german_age_numerical.csv")
sex = read.csv("german_sex_numerical.csv")
both = read.csv("german_sex-age_numerical.csv")
age$repair = "age"
sex$repair = "sex"
both$repair = "both"

df = rbind(age, sex, both) %>% 
  filter(algorithm %in% c("ZafarFairness", "Calders", "Kamishima", "Feldman-SVM"))
df$repair <- factor(df$repair, levels = c("age", "sex", "both"))

p = ggplot(df, aes(x=DIavgall, y=accuracy, colour=repair)) + catscale10 + catscale10_2 + stat_ellipse(geom="polygon", level=0.5, alpha=0.1) + geom_point(alpha=0.3) + ggtitle("German dataset") + facet_wrap(~algorithm)

print(p)
ggsave("paper-figures/german-multivariate-repair-tradeoff.png", p)
```

```{r}
race = read.csv("adult_race_numerical-binsensitive.csv")
sex = read.csv("adult_sex_numerical-binsensitive.csv")
both = read.csv("adult_race-sex_numerical-binsensitive.csv")
race$repair = "race"
sex$repair = "sex"
both$repair = "both"

df = rbind(race, sex, both) %>% 
  filter(algorithm %in% c("ZafarFairness", "Calders", "Kamishima", "Feldman-GaussianNB"))
df$repair <- factor(df$repair, levels = c("race", "sex", "both"))
p = ggplot(df, aes(x=DIbinary, y=accuracy, colour=repair)) + catscale10 + catscale10_2 + stat_ellipse(geom="polygon", level=0.5, alpha=0.1) + geom_point(alpha=0.3) + ggtitle("Adult dataset") + facet_wrap(~algorithm)
print(p)
ggsave("paper-figures/multiple_sensitive.png", p)
```

```{r}
measure_names = c("DIbinary", "DIavgall", "CV", "TNR", "accuracy", "BCR", "MCC", 
     "0-accuracy",
     "1-accuracy",
     
     "sensitive-accuracy", 
     "sensitive-calibration+",
     "sensitive-TNR",
     "sensitive-FNR",
     "sensitive-calibration-",
     "sensitive-TPR",
     "sensitive-FPR",

     "sensitive-accuracyDiff", 
     "sensitive-calibration+Diff",
     "sensitive-TNRDiff",
     "sensitive-FNRDiff",
     "sensitive-calibration-Diff",
     "sensitive-TPRDiff",
     "sensitive-FPRDiff",
     
     "TPR")

load_dataset = function(name, attribute) {
  dataset = read.csv(str_c(name, "_", attribute, "_numerical-binsensitive.csv"), stringsAsFactors = FALSE, check.names=FALSE)

  dataset$`sensitive-accuracy`     = dataset[,str_c(attribute, "-accuracy")]
  dataset$`sensitive-calibration+` = dataset[,str_c(attribute, "-calibration+")]
  dataset$`sensitive-calibration-` = dataset[,str_c(attribute, "-calibration-")]
  dataset$`sensitive-TNR`          = dataset[,str_c(attribute, "-TNR")]
  dataset$`sensitive-TPR`          = dataset[,str_c(attribute, "-TPR")]
  dataset$`sensitive-FNR`          = dataset[,str_c(attribute, "-FNR")]
  dataset$`sensitive-FPR`          = dataset[,str_c(attribute, "-FPR")]
  
  dataset$`sensitive-accuracyDiff`     = dataset[,str_c(attribute, "-accuracyDiff")]
  dataset$`sensitive-calibration+Diff` = dataset[,str_c(attribute, "-calibration+Diff")]
  dataset$`sensitive-calibration-Diff` = dataset[,str_c(attribute, "-calibration-Diff")]
  dataset$`sensitive-TNRDiff`          = dataset[,str_c(attribute, "-TNRDiff")]
  dataset$`sensitive-TPRDiff`          = dataset[,str_c(attribute, "-TPRDiff")]
  dataset$`sensitive-FNRDiff`          = dataset[,str_c(attribute, "-FNRDiff")]
  dataset$`sensitive-FPRDiff`          = dataset[,str_c(attribute, "-FPRDiff")]
  
  dataset$name = name
  dataset$attribute = attribute
  dataset[, c("name", "attribute", "algorithm", measure_names)]
}

make_correlation = function(dataset) {
  compute_measure_correlation_matrix(dataset, measure_names)
}

#dataset_name = "propublica-violent-recidivism"
#sensitive_attr = "sex-race"

#load_dataset(dataset_name, sensitive_attr) %>% 
#  make_correlation(.) %>% 
#  corrplot(., method="color", order="original", 
#           title=str_c(dataset_name, " - ", sensitive_attr, " - <all algorithms>"))
```

```{r}
plot_with_title = function(m, title) {
  corrplot(m, 
           method="color", order="original", 
           title=title,  
           mar=c(0,0,3,0)) 
}

dataset = "propublica_violent_recidivism"
sensitive_attribute = "race"

make_many_plots = function(dataset, sensitive_attr) {
  matrices = load_dataset(dataset, sensitive_attribute) %>% 
    group_by(algorithm) %>% 
    do(the_matrix = make_correlation(.))

  for (i in 1:nrow(matrices)) {
    plot_with_title(
      matrices[i,]$the_matrix[[1]], 
      str_c(dataset, " - ", attribute, " - ", matrices[i,]$algorithm))
  }
  matrices
}

make_many_plots(dataset, sensitive_attribute)
```

```{r}
load_dataset("propublica-violent-recidivism", "race")
```

```{r}
datasets = read.csv("all_numerical-binsensitive.csv")
datasets = map2(datasets$dataset, datasets$attribute, load_dataset)
datasets = bind_rows(datasets)
write.csv(datasets, "all_measures_numerical-binsensitive.csv")
```

```{r}
datasets %>%
  group_by(name, algorithm) %>% 
  do(mat = corrplot(make_correlation(.), method="color", order="original"), 
           title=str_c("<all attributes> - <all algorithms>"))
```