---
title: "KDD 2017 analysis"
author: "cscheid"
date: "2/9/2018"
output: html_document
---

# Function definitions, setup

```{r}
library(stringr)
library(ggplot2)
library(dplyr)
library(magrittr)
library(corrplot)
library(robust)
```

We'll be showing many different charts with a large number of different attributes, so a good
categorical color scale is helpful. We're using [d3](https://d3js.org) `d3.schemeCategory10` and `d3.schemeCategory20`.

```{r}
# Use these for more than 10 algorithms
colors_20 = c(
  "#1f77b4", "#aec7e8", "#ff7f0e", "#ffbb78", "#2ca02c", "#98df8a", "#d62728", "#ff9896",
  "#9467bd", "#c5b0d5", "#8c564b", "#c49c94", "#e377c2", "#f7b6d2", "#7f7f7f", "#c7c7c7",
  "#bcbd22", "#dbdb8d", "#17becf", "#9edae5")

# Use these for 10 or fewer algorithms
colors_10 = c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")

catscale10  = scale_colour_manual(values=colors_10)
catscale10_2 = scale_fill_manual(values=colors_10)

catscale20  = scale_colour_manual(values=colors_20)
catscale20_2 = scale_fill_manual(values=colors_20)

create_sensitivity_summary = function(df, x_var, y_var) {
  quo_x_var = enquo(x_var)
  quo_y_var = enquo(y_var)
  #x_mean_name = paste0("mean_", quo_name(quo_x_var))
  #y_mean_name = paste0("mean_", quo_name(quo_y_var))
  #x_sd_name = paste0("sd_", quo_name(quo_x_var))
  #y_sd_name = paste0("sd_", quo_name(quo_y_var))

  sensitivity_summary = 
    df %>% 
    group_by(algorithm) %>% 
    summarise(x_sd=sd(!!quo_x_var), x_mean=mean(!!quo_x_var), 
              y_sd=sd(!!quo_y_var), y_mean=mean(!!quo_y_var))
  sensitivity_summary
}

basic_sensitivity_plot = function(sensitivity_summary, x_var, y_var) {
  ggplot(sensitivity_summary, aes(x=x_mean, y=y_mean, colour=algorithm)) + catscale10 + catscale10_2 +
    xlab(quo_name(enquo(x_var))) + ylab(quo_name(enquo(y_var)))
}

plot_lines_sensitity_summary = function(basic_plot) {
  basic_plot + 
    geom_segment(aes(x=x_mean - x_sd, xend = x_mean + x_sd,
                     y=y_mean, yend = y_mean,
                     colour=algorithm)) + 
    geom_segment(aes(x=x_mean, xend = x_mean,
                     y=y_mean - y_sd, yend = y_mean + y_sd,
                     colour=algorithm))
}

plot_ellipses_sensitity_summary = function(basic_plot) {
  basic_plot + stat_ellipse(level=0.5, geom="polygon", aes(fill=algorithm), alpha=0.2) + stat_ellipse(level=0.5, fill=NA)
}

plot_rects_sensitivity_summary = function(basic_plot) {
  aesthetics1 = aes(xmin = x_mean - 0.5 * x_sd,   
                   xmax = x_mean + 0.5 * x_sd,
                   ymin = y_mean - 0.5 * y_sd, 
                   ymax = y_mean + 0.5 * y_sd,
                   fill=algorithm)
  aesthetics2 = aes(xmin = x_mean - 0.5 * x_sd,   
                   xmax = x_mean + 0.5 * x_sd,
                   ymin = y_mean - 0.5 * y_sd, 
                   ymax = y_mean + 0.5 * y_sd,
                   colour=algorithm)
  basic_plot +
    geom_rect(aesthetics1, alpha=0.15) +
    geom_rect(aesthetics2, fill=NA)
}

do_it_all = function(name, var1, var2, check.names=FALSE) {
  df = read.csv(str_c(name, ".csv"), check.names=check.names)
  
  x_var = as.name(var1)
  y_var = as.name(var2)

  sensitivity_summary = create_sensitivity_summary(df, !!x_var, !!y_var)

  basic_plot = basic_sensitivity_plot(sensitivity_summary, !!x_var, !!y_var) + ggtitle(name)
  
  plot_rects_sensitivity_summary(basic_plot)
}

nb_measure_comparison = function(name, measure) {
  num <- read.csv(str_c(name, "_numerical.csv"), check.names=FALSE)
  nbs <- read.csv(str_c(name, "_numerical-binsensitive.csv"), check.names=FALSE)
  
  var1 <- as.name(str_c(measure, "-numerical"))
  var2 <- as.name(str_c(measure, "-binsensitive"))
  
  df <- inner_join(num, nbs, by=c("algorithm", "run-id"), suffix = c("-numerical", "-binsensitive"))
  df$name = name
  df
  # return (df %>% select(!!var1, !!var2, "run-id", "algorithm", "name"))
}
```

# Preliminaries

# Paper figures

## Preprocessing tradeoffs

```{r}
plot_tradeoff = function(measure, dataset) {
  df = nb_measure_comparison(dataset, measure)
  var1 <- as.name(str_c(measure, "-numerical"))
  var2 <- as.name(str_c(measure, "-binsensitive"))
  ggplot(df %>% filter(!(algorithm %in% c("LR", "SVM", "GaussianNB"))), aes_q(x=var1, y=var2, colour=quote(algorithm))) + catscale10 + catscale10_2 + geom_abline(a=0,b=1, colour="gray") +
    geom_point() + ggtitle(str_c(dataset, ", measure: ", measure)) 
}

# measure = "accuracy"
p = plot_tradeoff("accuracy", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-accuracy.png", p)

p = plot_tradeoff("DIavgall", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-DIavgall.png", p)

p = plot_tradeoff("DIbinary", "german_sex-age")
print(p)
ggsave("paper-figures/preprocessing-tradeoff-DIbinary.png", p)
```
```{r}
p = plot_tradeoff("DIbinary", "german_sex-age")
print(p)
```

## Algorithm sensitivity

```{r}
plot_sensitivity = function(df, var1, var2) {
  x_var = as.name(var1)
  y_var = as.name(var2)

  sensitivity_summary = create_sensitivity_summary(df, !!x_var, !!y_var)
  basic_plot = basic_sensitivity_plot(sensitivity_summary, !!x_var, !!y_var)
  plot_rects_sensitivity_summary(basic_plot)
}

algos_to_plot = c(
  "ZafarFairness", "Calders", "SVM", 
  "Feldman-SVM", "DecisionTree", 
  "Feldman-DecisionTree", "Kamishima")

make_sensitivity_figure = function(name, var1="DIbinary", var2="accuracy") {
  df = read.csv(name, check.names=TRUE) %>% 
    filter(algorithm %in% algos_to_plot) %>% 
    mutate(algorithm=recode(algorithm, ZafarFairness="Zafar")) # rename to Zafar for clarity
  
  plot_sensitivity(df, var1, var2)
}

p = make_sensitivity_figure("adult_sex_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, sex attribute")
print(p)
ggsave("paper-figures/adult_sex_sensitivity.png", p)

p = make_sensitivity_figure("adult_race_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, race attribute")
print(p)
ggsave("paper-figures/adult_race_sensitivity.png", p)

p = make_sensitivity_figure("adult_race-sex_numerical-binsensitive.csv") +
  ggtitle("Adult dataset, sex+race combined attribute")
print(p)
ggsave("paper-figures/adult_race-sex_sensitivity.png", p)

```

```{r}
p = make_sensitivity_figure("propublica-violent-recidivism_race_numerical-binsensitive.csv", "DIavgall") +
  ggtitle("Propublica violent recidivism dataset, race attribute")
print(p)
```

### Parameter setting tradeoffs

Algorithms can state what their parameter grid search values are, since these can provide significantly different results:

```{r}
param_regex = "[01].[0-9]+"

adult_race_params = read.csv("paramgrid-results/Feldman-SVM-DIavgall_adult_race_numerical-binsensitive.csv", stringsAsFactors = FALSE, check.names=TRUE) %>% 
    mutate(lambda=as.numeric(str_extract(params, param_regex)))
p = ggplot(adult_race_params, aes(x=DIavgall, y=accuracy, colour=lambda)) + geom_point() + ggtitle("Adult dataset, race attribute")
print(p)
ggsave("paper-figures/adult_race_params_feldman.png", p)
```

```{r}
ricci_race_params = read.csv("paramgrid-results/ZafarFairness-DIavgall_ricci_Race_numerical-binsensitive.csv", stringsAsFactors = FALSE, check.names=FALSE) %>% 
  mutate(c=as.numeric(str_extract(params, param_regex))) %>% 
  filter(c>=0.01) # skip low range of parameter setting to avoid overweighting the correlation matrices
# ggplot(ricci_race_params, aes(x=DIavgall, y=`Race-calibration-`, colour=c)) + geom_point()
#adult_race_params = read.csv("ZafarFairness-DIavgall_adult_race_numerical-binsensitive.csv", #stringsAsFactors = FALSE, check.names=TRUE) %>% 
#  mutate(c=as.numeric(str_extract(params, param_regex))) %>% 
#  filter(c>=0.01) # skip low range of parameter setting to avoid overweighting the correlation matrices

p = ggplot(ricci_race_params, aes(x=DIavgall, y=accuracy, colour=c)) + geom_point() + ggtitle("Ricci dataset, Race attribute")
print(p)
ggsave("paper-figures/ricci_race_params_zafar.png", p)
```

### Proliferation of measures

```{r}
compute_measure_correlation_matrix = function(df, measures) {
  m = matrix(0, nrow=length(measures), ncol=length(measures))
  # colnames(m) = measures
  rownames(m) = measures
  for (i in 1:length(measures)) {
    for (j in 1:length(measures)) {
      x = df[[measures[[i]]]]
      y = df[[measures[[j]]]]
      if (sd(x) < 0.0001 || sd(y) < 0.0001) {
        m[i,j] = 0.0 # kludge
      } else {
        # some metrics have large outliers, which hoses a naive correlation calculation.
        # we'll use a robust correlation routine
        # we perturb the points minimally because otherwise robust:covRob crashes..
        tdf <- data.frame(x=x+rnorm(length(x))*0.001, 
                          y=y+rnorm(length(x))*0.001)
        if (cor(x, y) > 0.9999) {
          m[i, j] = cor(x, y)
        } else {
          r = covRob(tdf, corr=TRUE)
          # I could probably do all of this at once, but I don't want to deal with constant
          # columns _and_ robust calculations at once
          m[i,j] = r$cov[[1,2]]
        }
      }
    }
  }
  m
}
```

For Ricci and Zafar:

```{r}
# consistent_measures = c("DIbinary", "DIavgall", "CV", "TNR", "TPR", "accuracy", "BCR", "MCC")

# numeric_columns = sapply(ricci_race_params, class) == "numeric"
# ricci_measures = subset(colnames(ricci_race_params), numeric_columns)

# ricci_measures
# ricci_m = compute_measure_correlation_matrix(
#   ricci_race_params, 
#   c(consistent_measures[1:3], "Race-calibration-", 
#     consistent_measures[-(1:3)], "Race-accuracy", "0-accuracy", "1-accuracy", "Race-calibration+",
#     "Race-TNR", "Race-TPR"))

# symmetrize the matrix manually because robust correlation as we compute it is not
# necessarily symmetric


# BUG: I'm having a hard time making RMarkDown save this to a file :( type this in your
# console instead...
#
# png(file="paper-figures/ricci_measures_correlation.png")

# corrplot(ricci_m, method="color", order="original")
```

For Adult and Feldman-SVM:

```{r}
# numeric_columns = sapply(adult_race_params, class) == "numeric"
# adult_measures = subset(colnames(adult_race_params), numeric_columns)

# adult_m = compute_measure_correlation_matrix(
#   adult_race_params, 
#   c("X1.accuracy", "TPR", "race.TPR", "TNR", "X0.accuracy", "race.TNR", "race.calibration.", "BCR", "MCC", "accuracy", "race.accuracy", "race.calibration..1", "CV", "DIbinary", "DIavgall"))
  #c(consistent_measures[1:3], "race.calibration..1", 
  #  consistent_measures[-(1:3)], "race.accuracy", "X0.accuracy", "X1.accuracy", "race.calibration.",
  #  "race.TPR", "race.TNR"))

# BUG: I'm having a hard time making RMarkDown save this to a file :( type this in your
# console instead...
#
# corrplot(adult_m, method="color", order="original")
```

# Multiple sensitive attributes

```{r}
race = read.csv("adult_race_numerical.csv")
sex = read.csv("adult_sex_numerical.csv")
both = read.csv("adult_race-sex_numerical.csv")
race$repair = "race"
sex$repair = "sex"
both$repair = "both"

df = rbind(race, sex, both) %>% 
  filter(algorithm %in% c("ZafarFairness", "Calders", "Kamishima", "Feldman-GaussianNB"))
df$repair <- factor(df$repair, levels = c("race", "sex", "both"))
p = ggplot(df, aes(x=DIavgall, y=accuracy, colour=repair)) + catscale10 + catscale10_2 + stat_ellipse(geom="polygon", level=0.5, alpha=0.1) + geom_point(alpha=0.3) + ggtitle("Adult dataset") + facet_wrap(~algorithm)
print(p)
ggsave("paper-figures/adult-multivariate-repair-tradeoff.png", p)
```

```{r}
age = read.csv("german_age_numerical.csv")
sex = read.csv("german_sex_numerical.csv")
both = read.csv("german_sex-age_numerical.csv")
age$repair = "age"
sex$repair = "sex"
both$repair = "both"

df = rbind(age, sex, both) %>% 
  filter(algorithm %in% c("ZafarFairness", "Calders", "Kamishima", "Feldman-SVM"))
df$repair <- factor(df$repair, levels = c("age", "sex", "both"))

p = ggplot(df, aes(x=DIavgall, y=accuracy, colour=repair)) + catscale10 + catscale10_2 + stat_ellipse(geom="polygon", level=0.5, alpha=0.1) + geom_point(alpha=0.3) + ggtitle("German dataset") + facet_wrap(~algorithm)

print(p)
ggsave("paper-figures/german-multivariate-repair-tradeoff.png", p)
```
